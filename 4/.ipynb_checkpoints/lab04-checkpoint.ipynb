{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPlDDFMH-vYk"
   },
   "source": [
    "# **Lab 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQj7TOt5-KZm"
   },
   "source": [
    "## Data Wrangling\n",
    "\n",
    "In this lab, you will learn various ways of manipulating (including some cleaning) data such as merging data, duplicate removal, addressing missing data and transformation functions and mappings. You will also go through two sample use cases using car price data and minimum wage data, and proceed to apply some of these techniques learned earlier. Finally, the processed data is turned into some simple descriptive analytics to churn out meaningful insights from visualizations.\n",
    "\n",
    "> **Credit note:** A portion of this lab was adapted from [this fantastic tutorial](https://lectures.quantecon.org/py/pandas_panel.html) from QuantEcon and `prakharrathi25`'s [Kaggle kernel](https://www.kaggle.com/prakharrathi25/data-wrangling/) on data wrangling.\n",
    "\n",
    "> *From Introduction to Data Science (Tri 2020)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5r5FM4R-KZp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BMt_qZ0bBfs3"
   },
   "source": [
    "**Preparation**: Go ahead and upload all the data files needed in this lab to the Colab session (all 3 files).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IkqwYf5v-KZ2"
   },
   "source": [
    "<hr>\n",
    "\n",
    "Let's have a look at a classic dataset from UCI Machine Learning called the [Automobile Dataset](https://archive.ics.uci.edu/ml/datasets/automobile) which was later re-shared at Kaggle [here](https://www.kaggle.com/rickyrrii/old-car-price-data). This dataset is notoriously famous for being incomplete and noisy at best. In order for this data to be used for building a decent regression model (that is, a model that can predict car prices given a bunch of attributes), the data needs to be properly cleaned.\n",
    "\n",
    "The dataset is in the `.txt` file while the other `.names` file (open in any text editor) contains information of what are the attributes (columns) of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z4OhB28R-KZ4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "symboling            0\n",
       "normalized-losses    0\n",
       "make                 0\n",
       "fuel-type            0\n",
       "aspiration           0\n",
       "num-of-doors         0\n",
       "body-style           0\n",
       "drive-wheels         0\n",
       "engine-location      0\n",
       "wheel-base           0\n",
       "length               0\n",
       "width                0\n",
       "height               0\n",
       "curb-weight          0\n",
       "engine-type          0\n",
       "num-of-cylinders     0\n",
       "engine-size          0\n",
       "fuel-system          0\n",
       "bore                 0\n",
       "stroke               0\n",
       "compression-ratio    0\n",
       "horsepower           0\n",
       "peak-rpm             0\n",
       "city-mpg             0\n",
       "highway-mpg          0\n",
       "price                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type', 'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "cars = pd.read_csv('imports-85.data.txt', names=cols)\n",
    "print(cars.shape)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7QCCae9d-KaA"
   },
   "source": [
    "As we can see, there are some question marks appearing in the dataframe, and those are basically missing data that may hinder our further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ragSDiM9-KaD"
   },
   "source": [
    "### Cleaning Missing Data\n",
    "\n",
    "Pandas uses the floating point value '**NaN**' (Not a Number) to represent missing data in both floating and non-floating point arrays. It also has its use as a sentinel that can be easily detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WiHBjsEO-KaF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     aardvark\n",
      "1    artichoke\n",
      "2          NaN\n",
      "3      avocado\n",
      "dtype: object\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "string_data = pd.Series(['aardvark', 'artichoke', np.nan, 'avocado'])\n",
    "print(string_data)\n",
    "print(string_data.isnull())     # isnull() checks for values that are NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3t1aFvHc-KaM"
   },
   "source": [
    "Here are some NaN handling methods: `dropna`, `fillna`, `isnull`, `notnull`\n",
    "\n",
    "On a Series, it returns the Series with only the non-null data and index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bDeIXnTC-KaN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    NaN\n",
      "2    3.5\n",
      "3    NaN\n",
      "4    7.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series([1, np.nan, 3.5, np.nan, 7])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-pHyLTq-KaV"
   },
   "source": [
    "To simplify the use of `np.nan`, we can fix an alias `NA` for easy use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQSjscLU-KaX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    NaN\n",
      "2    3.5\n",
      "3    NaN\n",
      "4    7.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan as NA\n",
    "\n",
    "data = pd.Series([1, NA, 3.5, NA, 7])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Er5dhkhj-Kav"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "2    3.5\n",
      "4    7.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data[data.notnull()])     # notnull() acts as a boolean index for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HW8eYjW7-Ka3"
   },
   "source": [
    "With DataFrames, you may want to drop rows or columns which are all NA or just those containing any NAs. `dropna` by default drops any row containing a missing value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P4r6uQyq-Ka4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  NaN  NaN\n",
      "2  NaN  NaN  NaN\n",
      "3  NaN  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA], [NA, NA, NA], [NA, 6.5, 3.]])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4J3LLWtI-Ka-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "print(data.dropna()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJKxHQ2V-KbH"
   },
   "source": [
    "This seems so \"strict\"... As long as there is a single NaN, the row will be dropped.\n",
    "\n",
    "Passing `how='all'` will only drop rows that are all NA (watch row 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgroIR7s-KbI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  NaN  NaN\n",
      "3  NaN  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "print(data.dropna(how='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFMaHaCF-KbO"
   },
   "source": [
    "> **Note**: `axis=0` is default, that is row-wise, using `axis=1` indicate column-wise. Dropping columns in the same way is only a matter of passing `axis=1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZ-_QJRL-KbP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0    1    2\n",
      "0 NaN  6.5  3.0\n",
      "1 NaN  NaN  NaN\n",
      "2 NaN  NaN  NaN\n",
      "3 NaN  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "#Assign entire column as NA\n",
    "data[0] = NA\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJFEhUfU-Kbd"
   },
   "outputs": [],
   "source": [
    "print(data.dropna(axis=1, how='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h9-QnxsL-Kbr"
   },
   "source": [
    "Rather than filtering out missing data (and potentially discarding other data along with it), you may want to fill in the \"holes\" in several ways.\n",
    "\n",
    "Calling `fillna` with a constant replaces missing values with that value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GSD7pLq-Kbu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  NaN  NaN\n",
      "2  NaN  NaN  NaN\n",
      "3  NaN  6.5  3.0\n",
      "\n",
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  0.0  0.0\n",
      "2  0.0  0.0  0.0\n",
      "3  0.0  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA], [NA, NA, NA], [NA, 6.5, 3.]])\n",
    "print(data)\n",
    "print()\n",
    "print(data.fillna(0))   # fill with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bX6HPCF4-Kb3"
   },
   "source": [
    "Calling `fillna` with a dict, you can use a different fill value for each column. The keys in the dict denotes the column index, while its corresponding value denotes the replacement value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Xp4SxAw-Kb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  NaN  NaN\n",
      "2  NaN  NaN  NaN\n",
      "3  NaN  6.5  3.0\n",
      "\n",
      "     0    1    2\n",
      "0  1.0  6.5  3.0\n",
      "1  1.0  0.5 -1.0\n",
      "2  NaN  0.5 -1.0\n",
      "3  NaN  6.5  3.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA], [NA, NA, NA], [NA, 6.5, 3.]])\n",
    "print(data)\n",
    "print()\n",
    "print(data.fillna({1: 0.5, 2: -1}))   # fill in column 1 with 0.5 and column 2 with -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYY__sMk-Kb9"
   },
   "source": [
    "You can fill NA with the mean value of the data (can be either a good intuitive approach or a totally bad approach sometimes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRy8jwzr-Kb-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.000000\n",
      "1    3.833333\n",
      "2    3.500000\n",
      "3    3.833333\n",
      "4    7.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series([1., NA, 3.5, NA, 7])\n",
    "print(data.fillna(data.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q45s5gWN-KcG"
   },
   "source": [
    "Check out `fillna`'s function arguments: `value`, `method`, `axis`, `inplace`, `limit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tv4L041S-KcH"
   },
   "outputs": [],
   "source": [
    "?data.fillna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQdEsbfm-KcO"
   },
   "source": [
    "### Cleaning Duplicated Data\n",
    "\n",
    "The DataFrame method `duplicated()` returns a boolean Series indicating whether each row is a duplicate or not. Relatedly, `drop_duplicates()` returns a DataFrame without the duplicated entries (which are True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8vHlPck-KcO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    k1  k2\n",
      "0  one   1\n",
      "1  one   1\n",
      "2  one   2\n",
      "3  two   3\n",
      "4  two   3\n",
      "5  two   4\n",
      "6  two   4\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "5    False\n",
      "6     True\n",
      "dtype: bool\n",
      "\n",
      "    k1  k2\n",
      "0  one   1\n",
      "2  one   2\n",
      "3  two   3\n",
      "5  two   4\n"
     ]
    }
   ],
   "source": [
    "#remove duplicates\n",
    "data = pd.DataFrame({'k1': ['one'] * 3 + ['two'] * 4,\n",
    "'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "\n",
    "print(data)\n",
    "print(data.duplicated())\n",
    "print()\n",
    "print(data.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xPXJdL5-KcR"
   },
   "source": [
    "You can specify additional criteria to detect for duplicates. Suppose we had an additional column of values and we want to filter duplicates only based on the 'k1' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9a1mBcW-KcS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    k1  k2  v1\n",
      "0  one   1   0\n",
      "1  one   1   1\n",
      "2  one   2   2\n",
      "3  two   3   3\n",
      "4  two   3   4\n",
      "5  two   4   5\n",
      "6  two   4   6\n",
      "\n",
      "    k1  k2  v1\n",
      "0  one   1   0\n",
      "3  two   3   3\n"
     ]
    }
   ],
   "source": [
    "data['v1'] = range(7)    # add another column just to know which row is kept\n",
    "print(data)\n",
    "print()\n",
    "print(data.drop_duplicates(['k1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8C7Dbcap-KcV"
   },
   "source": [
    "---\n",
    "OK. Going back to the Automobile data, you can choose to convert the \"?\" symbols to NaN (which allow us to use those functions just now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tEr8WtF7-KcW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>...</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>122.0</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>122.0</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling  normalized-losses         make fuel-type aspiration  \\\n",
       "0          3              122.0  alfa-romero       gas        std   \n",
       "1          3              122.0  alfa-romero       gas        std   \n",
       "2          1              122.0  alfa-romero       gas        std   \n",
       "3          2              164.0         audi       gas        std   \n",
       "4          2              164.0         audi       gas        std   \n",
       "\n",
       "  num-of-doors   body-style drive-wheels engine-location  wheel-base  ...  \\\n",
       "0          two  convertible          rwd           front        88.6  ...   \n",
       "1          two  convertible          rwd           front        88.6  ...   \n",
       "2          two    hatchback          rwd           front        94.5  ...   \n",
       "3         four        sedan          fwd           front        99.8  ...   \n",
       "4         four        sedan          4wd           front        99.4  ...   \n",
       "\n",
       "   engine-size  fuel-system  bore  stroke compression-ratio horsepower  \\\n",
       "0          130         mpfi  3.47    2.68               9.0      111.0   \n",
       "1          130         mpfi  3.47    2.68               9.0      111.0   \n",
       "2          152         mpfi  2.68    3.47               9.0      154.0   \n",
       "3          109         mpfi  3.19    3.40              10.0      102.0   \n",
       "4          136         mpfi  3.19    3.40               8.0      115.0   \n",
       "\n",
       "   peak-rpm city-mpg  highway-mpg  price  \n",
       "0    5000.0       21           27  13495  \n",
       "1    5000.0       21           27  16500  \n",
       "2    5000.0       19           26  16500  \n",
       "3    5500.0       24           30  13950  \n",
       "4    5500.0       18           22  17450  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = cars.replace(\"?\", NA)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rtl97XDq-Kcb"
   },
   "source": [
    "Now, to quickly get the big picture of the condition of the data, we can try to find out how many NaNs are there in each of these columns. Remember: indices of a dataframe refer to the columns, so applying a function to a dataframe will be effective on the columns first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MVTJkuF-Kcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "symboling    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.isnull().sum()\n",
    "cars[[\"symboling\"]].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Ja1VDBV3lc3"
   },
   "source": [
    "Based on this summary, we can see that `normalized-loss` attribute has the most NaN values, while there are a few others also have incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpZBpGJ83S_h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "symboling              int64\n",
       "normalized-losses     object\n",
       "make                  object\n",
       "fuel-type             object\n",
       "aspiration            object\n",
       "num-of-doors          object\n",
       "body-style            object\n",
       "drive-wheels          object\n",
       "engine-location       object\n",
       "wheel-base           float64\n",
       "length               float64\n",
       "width                float64\n",
       "height               float64\n",
       "curb-weight            int64\n",
       "engine-type           object\n",
       "num-of-cylinders      object\n",
       "engine-size            int64\n",
       "fuel-system           object\n",
       "bore                  object\n",
       "stroke                object\n",
       "compression-ratio    float64\n",
       "horsepower            object\n",
       "peak-rpm              object\n",
       "city-mpg               int64\n",
       "highway-mpg            int64\n",
       "price                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.dtypes     # this shows all the data types within the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ulpmzD_g-Kce"
   },
   "source": [
    "Numeric operations such as mean or max cannot be applied to object types. Take this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4dotaeQ3CYj"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27711/2857611318.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"horsepower\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# try this as well:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# cars[\"horsepower\"].max()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10749\u001b[0m         )\n\u001b[1;32m  10750\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10753\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10369\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  10370\u001b[0m             \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10371\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10352\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10353\u001b[0m             )\n\u001b[0;32m> 10354\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  10355\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10356\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4390\u001b[0m                 )\n\u001b[1;32m   4391\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4392\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4394\u001b[0m     def _reindex_indexer(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     46\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "cars[\"horsepower\"].mean()\n",
    "# try this as well:\n",
    "# cars[\"horsepower\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3451jkWZ36TR"
   },
   "source": [
    "The right way to handle this is to force the conversion to numeric on a specific series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-1mxsdR33kU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "float64\n",
      "104.25615763546799\n"
     ]
    }
   ],
   "source": [
    "print(cars[\"horsepower\"].dtype)\n",
    "hp_num = pd.to_numeric(cars[\"horsepower\"], errors='coerce')\n",
    "print(hp_num.dtype)\n",
    "print(hp_num.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYUtvHIh3DVw"
   },
   "source": [
    "**Q1**: Replace the NaN data in `normalized-loss`, `peak-rpm`, `horsepower`, `bore`, `stroke` with their respective mean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yx1qnOSI-Kcf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>95.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>95.0</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>95.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>95.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>95.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     normalized-losses  peak-rpm  horsepower  bore  stroke\n",
       "0                122.0    5000.0       111.0  3.47    2.68\n",
       "1                122.0    5000.0       111.0  3.47    2.68\n",
       "2                122.0    5000.0       154.0  2.68    3.47\n",
       "3                164.0    5500.0       102.0  3.19    3.40\n",
       "4                164.0    5500.0       115.0  3.19    3.40\n",
       "..                 ...       ...         ...   ...     ...\n",
       "200               95.0    5400.0       114.0  3.78    3.15\n",
       "201               95.0    5300.0       160.0  3.78    3.15\n",
       "202               95.0    5500.0       134.0  3.58    2.87\n",
       "203               95.0    4800.0       106.0  3.01    3.40\n",
       "204               95.0    5400.0       114.0  3.78    3.15\n",
       "\n",
       "[205 rows x 5 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in here\n",
    "cars[\"normalized-losses\"]= pd.to_numeric(cars[\"normalized-losses\"],errors=\"coerce\")\n",
    "cars[\"normalized-losses\"]=cars[\"normalized-losses\"].fillna(cars[\"normalized-losses\"].mean())\n",
    "\n",
    "cars[\"peak-rpm\"]= pd.to_numeric(cars[\"peak-rpm\"],errors=\"coerce\")\n",
    "cars[\"peak-rpm\"]=cars[\"peak-rpm\"].fillna(cars[\"peak-rpm\"].mean())\n",
    "\n",
    "cars[\"horsepower\"]= pd.to_numeric(cars[\"horsepower\"],errors=\"coerce\")\n",
    "cars[\"horsepower\"]=cars[\"horsepower\"].fillna(cars[\"horsepower\"].mean())\n",
    "\n",
    "cars[\"bore\"]= pd.to_numeric(cars[\"bore\"],errors=\"coerce\")\n",
    "cars[\"bore\"]=cars[\"bore\"].fillna(cars[\"bore\"].mean())\n",
    "\n",
    "cars[\"stroke\"]= pd.to_numeric(cars[\"stroke\"],errors=\"coerce\")\n",
    "cars[\"stroke\"]=cars[\"stroke\"].fillna(cars[\"stroke\"].mean())\n",
    "\n",
    "\n",
    "cars[[\"normalized-losses\",\"peak-rpm\",\"horsepower\",\"bore\",\"stroke\"]]\n",
    "# note: Pandas cannot convert NaN to integer or floats, so to solve this\n",
    "# we need to convert the dataframe to numeric with errors=coerce option\n",
    "# after that, we can safely compute the mean, ignoring those "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      alfa-romero\n",
       "1      alfa-romero\n",
       "2      alfa-romero\n",
       "3             audi\n",
       "4             audi\n",
       "          ...     \n",
       "200          volvo\n",
       "201          volvo\n",
       "202          volvo\n",
       "203          volvo\n",
       "204          volvo\n",
       "Name: make, Length: 205, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.iloc[:,2] #this one gets all rows in a column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qteUfEIy-Kcl"
   },
   "source": [
    "Check again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Su0XtpL2-Kco"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "symboling            0\n",
       "normalized-losses    0\n",
       "make                 0\n",
       "fuel-type            0\n",
       "aspiration           0\n",
       "num-of-doors         0\n",
       "body-style           0\n",
       "drive-wheels         0\n",
       "engine-location      0\n",
       "wheel-base           0\n",
       "length               0\n",
       "width                0\n",
       "height               0\n",
       "curb-weight          0\n",
       "engine-type          0\n",
       "num-of-cylinders     0\n",
       "engine-size          0\n",
       "fuel-system          0\n",
       "bore                 0\n",
       "stroke               0\n",
       "compression-ratio    0\n",
       "horsepower           0\n",
       "peak-rpm             0\n",
       "city-mpg             0\n",
       "highway-mpg          0\n",
       "price                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UibFgmkf-Kcx"
   },
   "source": [
    "So we have not tackled the missing values in `num-of-doors` which appears to be a category, which is a string.\n",
    "\n",
    "Naively, we can replace the missing values with the most frequently appearing category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PShBJChz-Kcy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "four    114\n",
       "two      89\n",
       "Name: num-of-doors, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars[\"num-of-doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmmrbFnK-Kc1"
   },
   "source": [
    "Use the `idxmax()` function to directly pull out the value that corresponds to the item with the max value count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyXFaCuz-Kc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'four'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars[\"num-of-doors\"].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QPQrmd3-Kc4"
   },
   "source": [
    "Then, go ahead and replace the missing `num-of-doors` value by the most frequent value \"four\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KkKzK3ZP-Kc4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "symboling            0\n",
       "normalized-losses    0\n",
       "make                 0\n",
       "fuel-type            0\n",
       "aspiration           0\n",
       "num-of-doors         0\n",
       "body-style           0\n",
       "drive-wheels         0\n",
       "engine-location      0\n",
       "wheel-base           0\n",
       "length               0\n",
       "width                0\n",
       "height               0\n",
       "curb-weight          0\n",
       "engine-type          0\n",
       "num-of-cylinders     0\n",
       "engine-size          0\n",
       "fuel-system          0\n",
       "bore                 0\n",
       "stroke               0\n",
       "compression-ratio    0\n",
       "horsepower           0\n",
       "peak-rpm             0\n",
       "city-mpg             0\n",
       "highway-mpg          0\n",
       "price                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars[\"num-of-doors\"].replace({NA:\"four\"}, inplace=True) \n",
    "# inplace=True allows replacement to take place in the dataframe itself\n",
    "\n",
    "cars.isnull().sum()    # check again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUXRe8aK-Kc7"
   },
   "source": [
    "**Q2**: Drop all rows that do not have the price data. **Hint**: Use dropna(), specify which column to operate on with `subset` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCSNmylM-Kc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "symboling            0\n",
       "normalized-losses    0\n",
       "make                 0\n",
       "fuel-type            0\n",
       "aspiration           0\n",
       "num-of-doors         0\n",
       "body-style           0\n",
       "drive-wheels         0\n",
       "engine-location      0\n",
       "wheel-base           0\n",
       "length               0\n",
       "width                0\n",
       "height               0\n",
       "curb-weight          0\n",
       "engine-type          0\n",
       "num-of-cylinders     0\n",
       "engine-size          0\n",
       "fuel-system          0\n",
       "bore                 0\n",
       "stroke               0\n",
       "compression-ratio    0\n",
       "horsepower           0\n",
       "peak-rpm             0\n",
       "city-mpg             0\n",
       "highway-mpg          0\n",
       "price                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in here\n",
    "cars.dropna(subset=[\"price\"],inplace=True)\n",
    "\n",
    "cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxE-9R1w-Kc_"
   },
   "source": [
    "**Verify**: The data should have 201 rows after all the cleaning is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0cp_0ie-Kc_"
   },
   "outputs": [],
   "source": [
    "cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJUojJbF-KdC"
   },
   "outputs": [],
   "source": [
    "cars.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ovk9w0Bw-KdF"
   },
   "source": [
    "Notice from the data type printout above, some attributes have incorrect data types. For example, `bore` and `stroke` should both be numeric values (int or float), but they are assigned to be an object instead (such as a string) when the data was read earlier. This will cause problems in further processing that requires values to be numerical.\n",
    "\n",
    "To convert them into the appropriate data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PYKR1RPc-KdF"
   },
   "outputs": [],
   "source": [
    "cars[[\"bore\", \"stroke\"]] = cars[[\"bore\", \"stroke\"]].astype(\"float\")\n",
    "cars[[\"normalized-losses\"]] = cars[[\"normalized-losses\"]].astype(\"int\")\n",
    "cars[[\"price\"]] = cars[[\"price\"]].astype(\"float\")\n",
    "cars[[\"peak-rpm\"]] = cars[[\"peak-rpm\"]].astype(\"float\")\n",
    "cars[[\"horsepower\"]] = cars[[\"horsepower\"]].astype(\"int\")\n",
    "cars.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3o672XML-KdI"
   },
   "source": [
    "With all these steps, the data should now be clean and ready for further processing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_q23ytV7-KdJ"
   },
   "source": [
    "### Data Normalization\n",
    "\n",
    "Sometimes, you may want to normalize numeric data to reap its benefits during data modeling. Pandas does not have a normalize function, so you can either compute a normalization operation on the column itself, or you get Numpy's help to normalize values in the column. Typically, most normalizations want to scale the numeric values to a standard range (between 0 and 1 for e.g.), or to scale values according to the distribution such that the variance = 1 and average = 0.\n",
    "\n",
    "The car lengths looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwxR2x3q-KdJ"
   },
   "outputs": [],
   "source": [
    "cars['length'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZL-BdgQm-KdP"
   },
   "source": [
    "Normalizing by the maximum value is quite easy. Just divide all values by the max!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEfppit9-KdQ"
   },
   "outputs": [],
   "source": [
    "cars['length']/cars['length'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KtLzE1ro-KdT"
   },
   "source": [
    "This gives us an idea of how far is the relative length of each car from the length of the longest car.\n",
    "\n",
    "To directly replace the values in that column and also in the `width` and `height` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHk5Hd5l-KdT"
   },
   "outputs": [],
   "source": [
    "# make a deep copy - separate copy from the original cars2 = cars would not work, it's a shallow copy\n",
    "cars2 = cars.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvHpdOWA-KdX"
   },
   "outputs": [],
   "source": [
    "cars2['length'] = cars['length']/cars['length'].max()\n",
    "cars2['width'] = cars['width']/cars['width'].max()\n",
    "cars2['height'] = cars['height']/cars['height'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UeJShJWK-Kdb"
   },
   "outputs": [],
   "source": [
    "# check\n",
    "cars2[[\"length\", \"width\", \"height\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJI1HGFDKtvQ"
   },
   "source": [
    "A more common way of normalizing is to use both the minimum and maximum to adjust the values. This is called a min-max normalization.\n",
    "\n",
    "$$\\hat{x} = \\frac{x-x_{min}}{x_{max}-x_{min}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0YCLt2mR-Kdh"
   },
   "source": [
    "**Q3**: Compute the z-normalized value for `engine-size` and replace its values in `cars2` dataframe.\n",
    "\n",
    "$$\\hat{x} = \\frac{x-\\mu}{\\sigma}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gquYXFps-Kdi"
   },
   "outputs": [],
   "source": [
    "# fill in here\n",
    "\n",
    "\n",
    "# there are 2 other ways to do this: using pandas apply() with lambda function, use scipy.stats zscore function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbJmjM2--Kdp"
   },
   "source": [
    "### Data Transformation\n",
    "\n",
    "One of the methods that we have learned is **binning**, a process of grouping or categorizing numeric data into discrete \"bins\" or distinct baskets, which is one of the ways of dealing with noisy data.\n",
    "\n",
    "In this data, `horsepower` is a real valued variable ranging from 48 to 288, it has 57 unique values in total. What if we only care about the price difference between cars with \"high\" horsepower, \"medium\" horsepower, and \"low\" horsepower (3 types)? Can we rearrange them into three ‘bins' to simplify analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvhRiF5J-Kdq"
   },
   "outputs": [],
   "source": [
    "cars2[\"horsepower\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LrJGwibK-Kdy"
   },
   "source": [
    "To get an idea of how the values are distributed, use matplotlib library to plot its histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_kZeZj09-Kdz"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(cars2[\"horsepower\"])\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.xlabel(\"horsepower\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"horsepower bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sPHvc46C-Kd4"
   },
   "source": [
    "We want 3 bins of equal size so we can use Numpy's `linspace(start_value, end_value, numbers_generated)` function. To build 3 bins, we need to define 4 dividers or boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYYIYxK7-Kd4"
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(min(cars2[\"horsepower\"]), max(cars2[\"horsepower\"]), 4)\n",
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bts-r0ph-Kd8"
   },
   "source": [
    "So these are the dividers of the 3 bins, if we were to give it the starting value, ending value, and the number of values to be generated at equal intervals.\n",
    "\n",
    "Let's create the bin group names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owa8dSdM-Kd9"
   },
   "outputs": [],
   "source": [
    "group_names = ['Low', 'Medium', 'High']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeoemvuO-KeB"
   },
   "source": [
    "We can now apply the pandas function `cut` to determine what each value of horsepower belongs to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wbSLsxs-KeB"
   },
   "outputs": [],
   "source": [
    "cars2['horsepower-binned'] = pd.cut(cars2['horsepower'], bins, labels=group_names, include_lowest=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrCHz23z-KeE"
   },
   "outputs": [],
   "source": [
    "cars2[['horsepower','horsepower-binned']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRwKSc5w-KeH"
   },
   "outputs": [],
   "source": [
    "cars2[\"horsepower-binned\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Hx2oBX--KeN"
   },
   "source": [
    "Let's plot the distribution of the bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKYLwG7--KeN"
   },
   "outputs": [],
   "source": [
    "plt.bar(group_names, cars2[\"horsepower-binned\"].value_counts())\n",
    "\n",
    "# set x/y labels and plot title \n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Horsepower Bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qK1yOovA-KeQ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the dataframe again, you should see the new horsepower-binned column right at the end\n",
    "cars2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qz0KAnpn-KeR"
   },
   "source": [
    "If you are satisfied with the data you have cleaned so far, you can save it into a CSV file and store it away for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCNu5oS5-KeT"
   },
   "outputs": [],
   "source": [
    "# Convert to CSV file\n",
    "cars2.to_csv('car_data_CLEANED.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtYLBtqn-KeX"
   },
   "source": [
    "### Combining Data\n",
    "\n",
    "Sometimes we may encounter a situation where we have data coming in from multiple sources, and we want to combine the data into a single consolidated dataframe.\n",
    "\n",
    "Data contained in pandas objects can be combined together using a number of built-in functions. Among them are:\n",
    "\n",
    "* **`merge()`** connects rows in DataFrames based on one or more keys. Similar to *inner join* (intersection of keys) operation in RDBMS. Here's some visuals to refresh your memory...\n",
    "![DB joins](https://i.stack.imgur.com/1UKp7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VoVHiKUn-KeY"
   },
   "outputs": [],
   "source": [
    "# we have two DataFrames here, \n",
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)})\n",
    "df2 = pd.DataFrame({'key': ['a', 'b', 'd'], 'data2': range(3)})\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UFsfsQIf-Kee"
   },
   "outputs": [],
   "source": [
    "dfMerged = pd.DataFrame.merge(df1,df2)\n",
    "print(dfMerged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1d8LPRJK-Keg"
   },
   "source": [
    "Obviously, doing an *inner join* or a merging of two DataFrames by virtue of the intersection of the two makes sense if we have partial data coming from both sets of data. We can only be sure to preserve keys (and their respective values) that appear on *both* sets of data. An inner join discards data that only appear on one set of data -- for the case of data with key 'c' and 'd'.\n",
    "\n",
    "However, if you choose to trust all possible data coming from both Dataframes, you may opt for an \"outer\" merge. Incomplete data will automatically be assigned with a NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWD95W4h-Kei"
   },
   "outputs": [],
   "source": [
    "dfmergedOuter = pd.merge(df1, df2, how=\"outer\")\n",
    "print(dfmergedOuter)\n",
    "\n",
    "# you can also try 'left' and 'right' merge options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w5gCE5Yv-Kek"
   },
   "source": [
    "`concat()` glues or stacks together objects along an axis. DataFrames can be grouped along its rows (axis=0) or its columns (axis=1) (take note of the convention used in python in axis numbering). Compare the difference between a numpy concat and a pandas concat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUTLeMhn-Kel",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using numpy concatenate\n",
    "arr = np.arange(12).reshape((3, 4))\n",
    "print(arr)\n",
    "arrN=np.concatenate([arr, arr], axis=1)     # change to axis=0\n",
    "print(arrN)\n",
    "\n",
    "# pandas concat\n",
    "s1 = pd.Series([0, 1], index=['a', 'b'])\n",
    "s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e'])\n",
    "s3 = pd.Series([5, 6], index=['f', 'g'])\n",
    "\n",
    "concatSeries=pd.concat([s1, s2, s3], axis=1)  # change to axis=0 \n",
    "print(s1)\n",
    "print(s2)\n",
    "print(s3)\n",
    "print(concatSeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGU7MP14-Keo"
   },
   "source": [
    "By default, pandas concat works along axis=0 if unspecified.\n",
    "\n",
    "To provide column names for DataFrames, use the parameter `columns` to specify a list of corresponding column names. Upon combination multiple DataFrames, you can also specify keys for the merged subsets. This allows you to quickly access back the previously concatenated subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2NPArKY-Keo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data frames and column names\n",
    "df1 = pd.DataFrame(np.arange(6).reshape(3, 2), index=['a', 'b', 'c'], columns=['one', 'two'])\n",
    "print(df1)\n",
    "df2 = pd. DataFrame(5 + np.arange(4).reshape(2, 2), index=['a', 'c'], columns=['three', 'four'])\n",
    "print(df2)\n",
    "dfConcat=pd.concat([df1, df2], axis=1, keys=['level1', 'level2'])\n",
    "print(dfConcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCoQBm-5-Keq"
   },
   "outputs": [],
   "source": [
    "dfConcat['level2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eophr3Qu-Kev"
   },
   "source": [
    "## Use Case: OECD Minimum Wage Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4GXpIkL-Kev"
   },
   "source": [
    "Let's try our hand at another dataset containing the minimum wages collected from the [OECD](https://en.wikipedia.org/wiki/OECD) group of 32 countries.  \n",
    "\n",
    "The dataset in CSV has been provided: `oecd_minwage.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X25DEjPU-Kew"
   },
   "outputs": [],
   "source": [
    "wage = pd.read_csv('oecd_minwage.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkjOf0tZ-Key"
   },
   "source": [
    "Let's have a look at the dataframe (show first 5 frames):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-agdURui-Kez"
   },
   "outputs": [],
   "source": [
    "wage.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_BXBS8hN-Ke2"
   },
   "source": [
    "The current data condition is difficult to anlayze since there are several dimentions to the data, and that each of these dimensions seemed to be in different formats.\n",
    "\n",
    "Let's have a peek at various portions of the data. (Note: In pandas, `iloc` method allows direct positional access, just like how we would do for a numpy array.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O7JfT1pR-Ke2"
   },
   "outputs": [],
   "source": [
    "wage.iloc[7:11, 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_Veg1yg-Ke4"
   },
   "outputs": [],
   "source": [
    "wage.iloc[51:55, 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WehY6KZW-Ke5"
   },
   "outputs": [],
   "source": [
    "wage.iloc[260:264, 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGgU3_ss-Ke7"
   },
   "source": [
    "It appears that we have rows further down that belong to a different country, but contain the same 'Time' attribute. There are also information representing different 'Pay period'.\n",
    "\n",
    "If we were to analyze all these data based on the 'Time' (in other words, the year of the data), then we need to re-organize the data a little. This is where a **pivot table** comes into play. A pivot table performs some summarization or re-organization of the data into a more compact looking table so that it can be meaningfully interpreted or used further for visualization purposes.\n",
    "\n",
    "We will use `pivot_table` to create a wide format panel, with a `MultiIndex` to handle higher dimensional data. `pivot_table` arguments should specify the data (values), the index, and the columns we want in our resulting dataframe\n",
    "\n",
    "By passing a list in columns, we can create a MultiIndex in our column axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsNZsU7L-Ke7"
   },
   "outputs": [],
   "source": [
    "wage_pt = wage.pivot_table(values='value',\n",
    "                        index='Time',                                 # this is the new index of the pivot table\n",
    "                        columns=['Country', 'Series', 'Pay period'])  # this specifies grouped columns with multiple indices \n",
    "wage_pt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3E7us-5w-Ke-"
   },
   "source": [
    "To more easily filter our time series data later on, we will convert the index into a [`DateTimeIndex`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DatetimeIndex.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "li5kIIXS-Ke-"
   },
   "outputs": [],
   "source": [
    "wage_pt.index = pd.to_datetime(wage_pt.index)\n",
    "type(wage_pt.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uFiMhww6-Ke_"
   },
   "source": [
    "The columns contain multiple levels of indexing, known as a `MultiIndex`, with levels being ordered hierarchically (Country > Series > Pay period). This is known as \"concept hierarchy generation\".\n",
    "\n",
    "A `MultiIndex` is the simplest and most flexible way to manage panel data in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owMYoMMO-KfA"
   },
   "outputs": [],
   "source": [
    "type(wage_pt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4v5hwuKY-KfC"
   },
   "outputs": [],
   "source": [
    "wage_pt.columns.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nTnK6c-b-KfE"
   },
   "source": [
    "Like before, we can select the country (the top level of our MultiIndex):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zhkoIUKU-KfE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wage_pt['Japan'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPQ5tSgp-KfI"
   },
   "source": [
    "Here's a nifty trick if you need to look at the pivot table in a different way. \"Stacking\" and \"unstacking\" levels of the `MultiIndex` can be used to reshape the dataframe into a desired format.\n",
    "\n",
    "`stack()` rotates the lowest level of the column `MultiIndex` to the row index, while `unstack()` works in the opposite direction (try it out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmP_QAlDaXVC"
   },
   "outputs": [],
   "source": [
    "?wage_pt.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQKaRzoL-KfJ"
   },
   "outputs": [],
   "source": [
    "wage_pt.stack().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8MDUy45T-KfL"
   },
   "source": [
    "We can also pass in an argument to select the level we would like to stack (notice how it also auto-sorts that level in order)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9Qi5wur-KfL"
   },
   "outputs": [],
   "source": [
    "wage_pt.stack(level='Country').head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xzC7wqkI-KfN"
   },
   "source": [
    "Using `DatetimeIndex` for 'Time' makes it easy to select a particular time period.\n",
    "\n",
    "Selecting one year and stacking the two lower levels of the `MultiIndex` creates a cross-section of our panel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JXBq33d-KfO"
   },
   "outputs": [],
   "source": [
    "wage_pt['2016'].stack(level=(1,2)).transpose().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lwxSOBpU-KfR"
   },
   "source": [
    "To create a filtered dataframe that only takes the hourly minimum wages across countries and time, we can use the `xs()` method to select a cross-section of the data, taking values at lower levels in the multi-index, while keeping the higher levels (countries in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzZLVBNJ-KfR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wage_f = wage_pt.xs(('Hourly', 'In 2015 constant prices at 2015 USD exchange rates'),\n",
    "                     level=('Pay period', 'Series'), \n",
    "                     axis=1 )\n",
    "wage_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCwBgT4X-KfT"
   },
   "source": [
    "Now, this filtered dataframe looks good to be used for some analysis and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SdyiEN80-KfT"
   },
   "source": [
    "### Grouping and Summarizing data\n",
    "\n",
    "Grouping and summarizing data can be particularly useful for understanding large panel datasets. A simple way is to call an aggregation method on the dataframe, such as `.mean()` or `.max()` which is really quick and easy.\n",
    "\n",
    "For example, we can calculate the average real minimum wage for each country over the period 2006 to 2016 (the default is to aggregate over rows since rows typically constitute data samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOcCwinO-KfU",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wage_f.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LNXf0Chr-KfV"
   },
   "source": [
    "Using this, we can now plot the average minimum wage over a 10-year period (2006-2016) for each OECD country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjWsLlDr-KfV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.style.use('seaborn')        # use matplotlib but with seaborn styles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E13bwd1_-KfX"
   },
   "outputs": [],
   "source": [
    "# plotting can be done directly on the dataframe using\n",
    "wage_f.mean().sort_values(ascending=False).plot(kind='bar', title=\"Average minimum wage 2006 - 2016\")\n",
    "\n",
    "#Set country labels\n",
    "country_labels = wage_f.mean().sort_values(ascending=False).index.get_level_values('Country').tolist()\n",
    "plt.xticks(range(0, len(country_labels)), country_labels)\n",
    "plt.xlabel('Country')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dv1n5Lg9-KfZ"
   },
   "source": [
    "**Q4**: Figure out how to aggregate over columns, giving the average minimum wage for all countries over the time period. (Hint: the `axis` by default is aggregating over rows).This is what we call a *time series* graph, data over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ml2hxPz3-KfZ"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
